{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness Analysis\n",
    "\n",
    "Ideas:\n",
    "- sort nodes by different metrics and remove them in order.\n",
    "- groups nodes in different categories, sort the categories, and remove the nodes accordingly.\n",
    "\n",
    "Todo:\n",
    "- define all the metrics to track.\n",
    "\n",
    "Due-diligence:\n",
    "- calculate the compute time before pressing run.\n",
    "\n",
    "Possible Products:\n",
    "- static charts.\n",
    "- create gif for every metric.\n",
    "- create real-time refreshing dashboard."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "- Check that set of nodes of graph has same nodes as list of nodes with habitats\n",
    "- Extract unique values of habitats\n",
    "- Build habitat buckets (1 key for each unique value, no problem if count 2 in one bucket and 2 in another) (build one also for food groups)\n",
    "- Compute probability distribution of habitat buckets\n",
    "- Build node buckets with same key as habitat buckets\n",
    "- Retrieve random key according to probability distribution assigned to habitat buckets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOG\n",
    "- All nodes with rank food_group (not species) should not be removed in the perturbations, because they are to broad categories to ever die out.\n",
    "\n",
    "- Maybe calculate metrics modulo %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def habitat_bucket_probabilites(habitat_buckets, lost_habitat=['Grassland', '']):\n",
    "    \"\"\" \n",
    "    Food groups have a zero probability of being removed.\n",
    "    \"\"\"\n",
    "    proportions = []\n",
    "\n",
    "    foud_groups = habitat_buckets.popitem() \n",
    "\n",
    "    for hb in list(habitat_buckets.keys()):\n",
    "        proportions.append(len([s for s in hb if  s == lost_habitat]) / len(hb))  # TODO: grep string of habitats!!!!!!!!\n",
    "\n",
    "    n = len(proportions)\n",
    "    total = sum(proportions)\n",
    "    min_category_proportion = 0.05  # background extinction \n",
    "    smoothing = min_category_proportion * total / (1 - min_category_proportion * n)\n",
    "\n",
    "    smoothed_proportions = [p + smoothing for p in proportions]\n",
    "    total = sum(smoothed_proportions)\n",
    "    normalized_smoothed_proportions = [p / total for p in smoothed_proportions]\n",
    "\n",
    "    normalized_smoothed_proportions.append(0) \n",
    "    habitat_buckets['food_groups'] = foud_groups\n",
    "\n",
    "    return normalized_smoothed_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def habitat_buckets(nodes_df):\n",
    "    habitats = pd.unique(nodes_df['habitat'])\n",
    "\n",
    "    buckets = {}  # Changed variable name here\n",
    "\n",
    "    for habitat in habitats:\n",
    "        buckets[habitat] = []\n",
    "\n",
    "    # mock result\n",
    "    buckets = {\n",
    "        ('g'): (), \n",
    "        ('g', 'other'): (),\n",
    "        ('g', 'other', 'other'): (),\n",
    "        ('other'): (),\n",
    "        ('food_groups'): ()  # pay special attention to this one \n",
    "    }\n",
    "\n",
    "    return buckets  # And here\n",
    "\n",
    "def bucket_probabilities(habitat_buckets):\n",
    "    normalized_smoothed_proportions = habitat_bucket_probabilites(habitat_buckets, 'g')\n",
    "    return normalized_smoothed_proportions\n",
    "\n",
    "def habitat_buckets_and_probabilities(nodes_df):\n",
    "    buckets = habitat_buckets(nodes_df)  # Changed function call here\n",
    "    habitat_probabilities = bucket_probabilities(buckets)  # And here\n",
    "\n",
    "    # add nodes to habitat buckets\n",
    "    for _, row in nodes_df.iterrows():\n",
    "        node = row['specie']\n",
    "        habitat = row['habitat']\n",
    "        buckets[habitat].append(node)  # And here\n",
    "\n",
    "    return buckets, habitat_probabilities  # And finally here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_node(buckets, habitat_probabilities):\n",
    "    # Choose a bucket\n",
    "    bucket_keys = list(buckets.keys())\n",
    "    chosen_bucket = np.random.choice(bucket_keys, p=habitat_probabilities)\n",
    "\n",
    "    # Choose a node from the bucket\n",
    "    nodes_in_bucket = buckets[chosen_bucket]\n",
    "    chosen_node = np.random.choice(nodes_in_bucket)\n",
    "\n",
    "    return chosen_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = 'node_lists/all_species_and_feeding_groups'\n",
    "nodes_df = pd.DataFrame(data=csv, columns=['specie', 'habitat'])\n",
    "n = len(nodes_df)\n",
    "\n",
    "buckets, habitat_probabilities = habitat_buckets_and_probabilities(csv)\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "for i in range(n):\n",
    "    node = choose_node(buckets, habitat_probabilities)\n",
    "    node_removal(node)\n",
    "\n",
    "    # compute metrics\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
